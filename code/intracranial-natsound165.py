import os
import hdf5storage
import torch
# import torchaudio
# from utils.hubert import generate_HUBERT_features

# from utils.ast import generate_AST_features
from utils.cochdnn import generate_CochDNN_features
from utils.cochdnn import build_model as build_model_cochdnn
from utils.cochresnet import generate_CochResNet_features
from utils.cochresnet import build_model as build_model_cochresnet
from utils.pc import generate_pc
# import numpy as np
# from transformers import AutoModel

######personalize parameters
device = torch.device("cuda:0")
compile_torch = True
sr = 25
pc = 100


####################intracranial-natsound165####################

mat = hdf5storage.loadmat(
    "/home/gliao2/snormanh_lab_shared/projects/intracranial-natsound165/stimuli/stim_names.mat"
)
stim_names = mat["stim_names"]
output_root = "/scratch/snormanh_lab/shared/projects/intracranial-natsound165/analysis"
wav_dir = "/scratch/snormanh_lab/shared/projects/intracranial-natsound165/stimuli/stimulus_audio"


# #######cochleagram########
# # do not need to generate cochleagram features since they are already generated by matlab
# feature_name = "cochleagram"
# wav_features = []
# print("loading cochleagram features")
# for stim_index, stim_name in enumerate(stim_names):
#     wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
#     feature_path = f"{output_root}/features/{feature_name}/original/{stim_name}.mat"
#     feature = hdf5storage.loadmat(feature_path)["features"]
#     wav_features.append(feature)
# print("computing PCs of cochleagram features")
# pca_pipeline = generate_pc(
#     wav_features,
#     pc,
#     output_root,
#     feature_name,
#     stim_names,
#     demean=True,
#     std=False,
# )
# generate_pc(
#     wav_features,
#     pc,
#     output_root,
#     feature_name,
#     stim_names,
#     demean=True,
#     std=False,
#     pca_pipeline=pca_pipeline,
# )

# #######spectrotemporal model(modulus)########
# # do not need to generate cochleagram features since they are already generated by matlab
# feature_name = "spectrotemporal"
# variant = "modulus"
# wav_features = []
# print("loading spectrotemporal modulus features")
# for stim_index, stim_name in enumerate(stim_names):
#     wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
#     feature_path = f"{output_root}/features/{feature_name}/{variant}/{stim_name}.mat"
#     feature = hdf5storage.loadmat(feature_path)["features"]
#     wav_features.append(feature)
# print("computing PCs of spectrotemporal modulus features")
# pca_pipeline = generate_pc(
#     wav_features,
#     pc,
#     output_root,
#     feature_name,
#     stim_names,
#     demean=True,
#     std=False,
#     variant=variant,
# )
# generate_pc(
#     wav_features,
#     pc,
#     output_root,
#     feature_name,
#     stim_names,
#     demean=True,
#     std=False,
#     pca_pipeline=pca_pipeline,
#     variant=variant,
# )


# #######spectrotemporal model(real)########
# # do not need to generate cochleagram features since they are already generated by matlab
# feature_name = "spectrotemporal"
# variant = "real"
# wav_features = []
# print("loading spectrotemporal real features")
# for stim_index, stim_name in enumerate(stim_names):
#     wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
#     feature_path = f"{output_root}/features/{feature_name}/{variant}/{stim_name}.mat"
#     feature = hdf5storage.loadmat(feature_path)["features"]
#     wav_features.append(feature)
# print("computing PCs of spectrotemporal real features")
# pca_pipeline = generate_pc(
#     wav_features,
#     pc,
#     output_root,
#     feature_name,
#     stim_names,
#     demean=True,
#     std=False,
#     variant=variant,
# )
# generate_pc(
#     wav_features,
#     pc,
#     output_root,
#     feature_name,
#     stim_names,
#     demean=True,
#     std=False,
#     pca_pipeline=pca_pipeline,
#     variant=variant,
# )


# #######HUBERT########
# # generate hubert features
# HUBERT_bundle = torchaudio.pipelines.HUBERT_BASE
# HUBERT_model = HUBERT_bundle.get_model().to(device)
# if compile_torch:
#     HUBERT_model = torch.compile(HUBERT_model)
# for stim_index, stim_name in enumerate(stim_names):
#     wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
#     generate_HUBERT_features(
#         device, HUBERT_model, wav_path, output_root, n_t=None, out_sr=sr
#     )

# # compute PC of hubert features
# feature_name = "hubert"
# layer_num = 19
# for layer in range(layer_num):
#     wav_features = []
#     for stim_index, stim_name in enumerate(stim_names):
#         wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
#         feature_path = (
#             f"{output_root}/features/{feature_name}/layer{layer}/{stim_name}.mat"
#         )
#         feature = hdf5storage.loadmat(feature_path)["features"]
#         wav_features.append(feature)
#     pca_pipeline = generate_pc(
#         wav_features,
#         pc,
#         output_root,
#         feature_name,
#         stim_names,
#         demean=True,
#         std=False,
#         variant=f"layer{layer}",
#     )
#     generate_pc(
#         wav_features,
#         pc,
#         output_root,
#         feature_name,
#         stim_names,
#         demean=True,
#         std=False,
#         variant=f"layer{layer}",
#         pca_pipeline=pca_pipeline,
#     )


# #######AST########
# # generate AST features
# AST_model = AutoModel.from_pretrained("MIT/ast-finetuned-audioset-10-10-0.4593").to(
#     device
# )

# for stim_index, stim_name in enumerate(stim_names):
#     wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
#     generate_AST_features(device, AST_model, wav_path, output_root, n_t=None, out_sr=sr)

# # compute PC of ast features
# feature_name = "ast"
# layer_num = 14
# for layer in range(layer_num):
#     wav_features = []
#     for stim_index, stim_name in enumerate(stim_names):
#         wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
#         feature_path = (
#             f"{output_root}/features/{feature_name}/layer{layer}/{stim_name}.mat"
#         )
#         feature = hdf5storage.loadmat(feature_path)["features"]
#         wav_features.append(feature)
#     pca_pipeline = generate_pc(
#         wav_features,
#         pc,
#         output_root,
#         feature_name,
#         stim_names,
#         demean=True,
#         std=False,
#         variant=f"layer{layer}",
#     )
#     generate_pc(
#         wav_features,
#         pc,
#         output_root,
#         feature_name,
#         stim_names,
#         demean=True,
#         std=False,
#         variant=f"layer{layer}",
#         pca_pipeline=pca_pipeline,
#     )


# #######CochDNN########
# # generate CochDNN features
# CochDNN_model = build_model_cochdnn()
# variant = "kell2018_wsa"
# for stim_index, stim_name in enumerate(stim_names):
#     wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
#     generate_CochDNN_features(
#         device=device,
#         model=CochDNN_model,
#         wav_path=wav_path,
#         output_root=output_root,
#         n_t=None,
#         out_sr=sr,
#         variant=variant,
#     )

# # compute PC of cochdnn features
# feature_name = "cochdnn"
# layer_num = 6
# for layer in range(layer_num):
#     wav_features = []
#     for stim_index, stim_name in enumerate(stim_names):
#         wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
#         feature_path = f"{output_root}/features/{feature_name}/{variant}_layer{layer}/{stim_name}.mat"
#         feature = hdf5storage.loadmat(feature_path)["features"]
#         wav_features.append(feature)
#     pca_pipeline = generate_pc(
#         wav_features,
#         pc,
#         output_root,
#         feature_name,
#         stim_names,
#         demean=True,
#         std=False,
#         variant=f"{variant}_layer{layer}",
#     )
#     generate_pc(
#         wav_features,
#         pc,
#         output_root,
#         feature_name,
#         stim_names,
#         demean=True,
#         std=False,
#         variant=f"{variant}_layer{layer}",
#         pca_pipeline=pca_pipeline,
#     )


#######CochResNet########
# generate CochResNet features
CochResNet_model = build_model_cochresnet()
variant = "cochresnet_wsa"
for stim_index, stim_name in enumerate(stim_names):
    wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
    generate_CochResNet_features(
        device=device,
        model=CochResNet_model,
        wav_path=wav_path,
        output_root=output_root,
        n_t=None,
        out_sr=sr,
        variant=variant,
    )

# compute PC of cochresnet features
feature_name = "cochresnet"
layer_num = 6
for layer in range(layer_num):
    wav_features = []
    for stim_index, stim_name in enumerate(stim_names):
        wav_path = os.path.join(wav_dir, f"{stim_name}.wav")
        feature_path = f"{output_root}/features/{feature_name}/{variant}_layer{layer}/{stim_name}.mat"
        feature = hdf5storage.loadmat(feature_path)["features"]
        wav_features.append(feature)
    pca_pipeline = generate_pc(
        wav_features,
        pc,
        output_root,
        feature_name,
        stim_names,
        demean=True,
        std=False,
        variant=f"{variant}_layer{layer}",
    )
    generate_pc(
        wav_features,
        pc,
        output_root,
        feature_name,
        stim_names,
        demean=True,
        std=False,
        variant=f"{variant}_layer{layer}",
        pca_pipeline=pca_pipeline,
    )
